name: Ollama
tags:
  - AI
title: 本地大模型推理服务（Docker Compose）
description: 通过 Docker Compose 运行 Ollama，并由 `anya-backend` Web/API 进行模型列表、下载与对话。
additionalProperties:
  key: ollama
  name: Ollama
  tags:
    - AI
  shortDescZh: Ollama（Compose）控制与对话
  shortDescEn: Control Ollama (Compose) and chat
  type: runtime
  website: https://ollama.com/
  github: https://github.com/ollama/ollama
  gpuSupport: true
  defaultPort: 11434
  anya:
    installType: compose
    baseURL: http://127.0.0.1:11434
    # System capability: can't be uninstalled and shouldn't appear on the home/app list.
    removable: false
    hidden: true
